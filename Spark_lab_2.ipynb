{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e20c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the session\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", \"4050\")\n",
    "conf.set(\"spark.app.name\", \"mlops_lab_2_danilov\")\n",
    "conf.set(\"spark.master\", \"local\")\n",
    "conf.set(\"spark.executor.cores\", \"12\")\n",
    "conf.set(\"spark.executor.instances\", \"1\")\n",
    "conf.set(\"spark.executor.memory\", \"16g\")\n",
    "conf.set(\"spark.locality.wait\", \"0\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "conf.set(\"spark.kryoserializer.buffer.max\", \"2000\")\n",
    "conf.set(\"spark.executor.heartbeatInterval\", \"6000s\")\n",
    "conf.set(\"spark.network.timeout\", \"10000000s\")\n",
    "conf.set(\"spark.shuffle.spill\", \"true\")\n",
    "conf.set(\"spark.driver.memory\", \"16g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e610a4",
   "metadata": {},
   "source": [
    "### сконкатенируем все файлы train разбиения, но по памяти ограничим каждый набор 50000 записей, чтобы не было memoryerror (мы на одной машине с 16gb оперативки)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8456b",
   "metadata": {},
   "source": [
    "Подготовим данные для чтения в `sc.binaryFiles`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff7080",
   "metadata": {},
   "source": [
    "Для выдачи рекомендаций обращаемся к исходным данным по айди пользователя, наиболее похожего на нашего. Если у наиболее похожего юзера не хватает рекомендаций, идем к следующему по схожести. Фильтруем дубликаты, чтобы не рекомендовать фильмы, просмотренные таргетным пользователем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f62170e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommederSystem:\n",
    "    def __init__(self, data_dir='ml-20mx16x32/', data_target_dir='train', mode='train'):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_target_dir = data_target_dir\n",
    "        os.makedirs(self.data_target_dir, exist_ok=True)\n",
    "        data_files = os.listdir(self.data_dir)\n",
    "        data_files = [os.path.join(self.data_target_dir, fname) for fname in data_files if mode in fname]\n",
    "        \n",
    "        for npz_path in data_files:\n",
    "            shutil.copyfile(os.path.join(self.data_dir, npz_path.split(os.sep)[1]), npz_path)\n",
    "        npz_rdd = sc.binaryFiles(self.data_target_dir)\n",
    "        npz_rdd = npz_rdd.map(lambda l: np.load(BytesIO(l[1]))['arr_0'][:500].astype(int).tolist())\\\n",
    "                        .flatMap(lambda x: x).groupByKey() \\\n",
    "                        .map(lambda x: (int(x[0]), list(x[1])))\n",
    "        \n",
    "        schema = T.StructType([T.StructField(\"user_id\", T.IntegerType(), True), \n",
    "                               T.StructField(\"movie_id\", T.ArrayType(T.IntegerType()), True)])\n",
    "        self.dataset = npz_rdd.toDF(schema=schema)\n",
    "        self.dataset.show()\n",
    "        \n",
    "    def calc_tf_idf(self):\n",
    "        hashingTF = HashingTF(inputCol=\"movie_id\", outputCol=\"tf_features\", numFeatures=1000)\n",
    "        tf = hashingTF.transform(self.dataset)\n",
    "        tf.cache()\n",
    "        idf = IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\").fit(tf)\n",
    "        self.tfidf = idf.transform(tf)\n",
    "    \n",
    "    def sample_random_user(self):\n",
    "        \"\"\"Генерирует id случайного пользователя, для которого нужно сделать рекомендации.\"\"\"\n",
    "        unique_users_id = [user.user_id for user in self.dataset.select('user_id').distinct().collect()]\n",
    "        self.user_id = int(np.random.choice(unique_users_id, 1)[0])\n",
    "        return self.user_id\n",
    "    \n",
    "    def calc_similarity_matrix(self, target_user: int):\n",
    "        if not hasattr(self, 'tfidf'):\n",
    "            self.calc_tf_idf()\n",
    "        mat = IndexedRowMatrix(\n",
    "            self.tfidf.select(\"user_id\", \"tfidf_features\")\\\n",
    "            .rdd.map(lambda row: IndexedRow(row.user_id, row.tfidf_features.toArray()))).toBlockMatrix()\n",
    "        sim_matrix = mat.transpose().toIndexedRowMatrix().columnSimilarities()\n",
    "        sim_matrix = sim_matrix.entries.filter(lambda x: x.i == target_user or x.j == target_user)\n",
    "        self.sorted_similarity = sim_matrix.sortBy(lambda x: x.value, ascending=False) \\\n",
    "                            .map(lambda x: IndexedRow(x.j if x.i == target_user else x.i,  Vectors.dense(x.value)))\n",
    "        self.sim_users_ids = [user_info.index for user_info in self.sorted_similarity.collect()]\n",
    "\n",
    "    def get_movies_by_user(self, sim_user_id: int, movies_not_to_recom: list):\n",
    "        most_similar_user_movies = self.dataset.filter(self.dataset.user_id == sim_user_id).select(\"movie_id\").rdd\n",
    "        most_similar_user_movies = set(most_similar_user_movies.collect()[0].movie_id)\n",
    "        movies_not_to_recom = set(movies_not_to_recom)\n",
    "        intersect_with_target_user = set.intersection(most_similar_user_movies, movies_not_to_recom)\n",
    "        new_movies = most_similar_user_movies - intersect_with_target_user\n",
    "        new_movies = list(new_movies)\n",
    "        return new_movies\n",
    "    \n",
    "    def get_recommendations(self, target_user_id: int, number_of_reccomendations: int = 30):\n",
    "        if not self.sim_users_ids:\n",
    "            return 'Check similar users id list - call calc_similarity_matrix for specified user_id'\n",
    "        recommended_movies = []\n",
    "        target_user_movies = self.dataset.filter(self.dataset.user_id == target_user_id).select(\"movie_id\").rdd\n",
    "        target_user_movies = target_user_movies.collect()[0].movie_id\n",
    "        while len(recommended_movies) < number_of_reccomendations and len(self.sim_users_ids) != 0:\n",
    "            next_most_similar_user_id = self.sim_users_ids.pop(0)\n",
    "            new_movies = self.get_movies_by_user(next_most_similar_user_id, recommended_movies)\n",
    "            recommended_movies.extend(new_movies)\n",
    "        recommended_movies = recommended_movies[:number_of_reccomendations]\n",
    "        return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "212931b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|            movie_id|\n",
      "+-------+--------------------+\n",
      "|      0|[16981, 23846, 27...|\n",
      "| 138240|[308, 653, 936, 1...|\n",
      "|1382400|[1395, 1809, 2550...|\n",
      "|1520640|[2685, 4199, 5596...|\n",
      "|1658880|[98, 1706, 1834, ...|\n",
      "|1797120|[8340, 9318, 9803...|\n",
      "|1935360|[709, 822, 3436, ...|\n",
      "|2073600|[154, 4513, 16294...|\n",
      "| 276480|[1200, 3517, 5843...|\n",
      "| 414720|[188, 640, 673, 6...|\n",
      "| 552960|[1906, 2227, 3299...|\n",
      "| 691200|[5682, 17550, 347...|\n",
      "| 829440|[22361, 31549, 34...|\n",
      "| 967680|[164, 2600, 3050,...|\n",
      "|1105920|[1507, 1662, 2451...|\n",
      "|1244160|[2953, 4614, 4983...|\n",
      "|      1|[29269, 29384, 30...|\n",
      "|1382401|[7684, 20040, 237...|\n",
      "|1797121|[722, 15782, 2703...|\n",
      "|1935361|[32442, 53672, 58...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recsystem = RecommederSystem(data_dir='ml-20mx16x32/', data_target_dir='train', mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6832bfbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id случайного пользователя: 276480\n"
     ]
    }
   ],
   "source": [
    "user_id = recsystem.sample_random_user()\n",
    "print('Id случайного пользователя:', user_id)\n",
    "recsystem.calc_similarity_matrix(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e900b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рекомендованые фильмы: \n",
      " [355330, 350211, 363523, 138246, 366599, 361467, 360461, 293902, 355342, 178203, 45085, 366622, 366629, 363557, 251943, 352295, 7206, 349228, 290861, 178223, 362543, 363570, 44084, 106551, 354360, 25655, 266301, 364609, 351299, 346181]\n"
     ]
    }
   ],
   "source": [
    "recommendations = recsystem.get_recommendations(user_id, number_of_reccomendations=30)\n",
    "print('Рекомендованые фильмы: \\n', recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
